{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/reinforcement-learning/atari-on-distributed-compute/pong_rllib.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning in Azure Machine Learning - Pong problem\n",
    "Reinforcement Learning in Azure Machine Learning is a managed service for running distributed reinforcement learning training and simulation using the open source Ray framework.\n",
    "This example uses Ray RLlib to train a Pong playing agent on a multi-node cluster.\n",
    "\n",
    "## Pong problem\n",
    "[Pong](https://en.wikipedia.org/wiki/Pong) is a two-dimensional sports game that simulates table tennis. The player controls an in-game paddle by moving it vertically across the left or right side of the screen. They can compete against another player controlling a second paddle on the opposing side. Players use the paddles to hit a ball back and forth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "      <th style=\"text-align: center;\"><img src=\"./images/pong.gif\" alt=\"Pong image\" align=\"middle\" margin-left=\"auto\" margin-right=\"auto\"/></th>\n",
    "  </tr>\n",
    "  <tr style=\"text-align: center;\">\n",
    "      <th>Fig 1. Pong game animation (from <a href=\"https://towardsdatascience.com/intro-to-reinforcement-learning-pong-92a94aa0f84d\">towardsdatascience.com</a>).</th>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to train an agent to win an episode of Pong game against opponent with the score of at least 18 points. An episode in Pong runs until one of the players reaches a score of 21. Episodes are a terminology that is used across all the [OpenAI gym](https://gym.openai.com/envs/Pong-v0/) environments that contains a strictly defined task.\n",
    "\n",
    "Training a Pong agent is a compute-intensive task and this example demonstrates the use of Reinforcement Learning in Azure Machine Learning service to train an agent faster in a distributed, parallel environment. You'll learn more about using the head and the worker compute targets to train an agent in this notebook below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "It is highly recommended that the user should go through the [Reinforcement Learning in Azure Machine Learning - Cartpole Problem on Single Compute](../cartpole-on-single-compute/cartpole_sc.ipynb) to understand the basics of Reinforcement Learning in Azure Machine Learning and Ray RLlib used in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Development Environment\n",
    "The following subsections show typical steps to setup your development environment. Setup includes:\n",
    "\n",
    "* Connecting to a workspace to enable communication between your local machine and remote resources\n",
    "* Creating an experiment to track all your runs\n",
    "* Setting up a virtual network\n",
    "* Creating remote head and worker compute target on a virtual network to use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure Machine Learning SDK\n",
    "Display the Azure Machine Learning SDK version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure Machine Learning SDK Version:  1.33.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Azure Machine Learning core imports\n",
    "import azureml.core\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"Azure Machine Learning SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Azure Machine Learning workspace\n",
    "Get a reference to an existing Azure Machine Learning workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lukasml | northeurope | ragweed\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep = ' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure Machine Learning experiment\n",
    "Create an experiment to track the runs in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "# Experiment name\n",
    "experiment_name = 'rllib-pong-multi-node'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Virtual Network and Network Security Group\n",
    "\n",
    "**If you are using separate compute targets for the Ray head and worker, as we do in this notebook**, a virtual network must be created in the resource group.  If you have already created a virtual network in the resource group, you can skip this step.\n",
    "\n",
    "> Note that your user role must have permissions to create and manage virtual networks to run the cells below. Talk to your IT admin if you do not have these permissions.\n",
    "\n",
    "#### Create Virtual Network\n",
    "To create the virtual network you first must install the [Azure Networking Python API](https://docs.microsoft.com/python/api/overview/azure/network?view=azure-python).\n",
    "\n",
    "`pip install --upgrade azure-mgmt-network`\n",
    "\n",
    "Note: In this section we are using [DefaultAzureCredential](https://docs.microsoft.com/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python)\n",
    "class for authentication which, by default, examines several options in turn, and stops on the first option that provides\n",
    "a token. You will need to log in using Azure CLI, if none of the other options are available (please find more details [here](https://docs.microsoft.com/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-mgmt-network in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (19.0.0)\n",
      "Requirement already satisfied: msrest>=0.6.21 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from azure-mgmt-network) (0.6.21)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from azure-mgmt-network) (1.1.27)\n",
      "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from azure-mgmt-network) (1.3.0)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.15.0 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-network) (1.17.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-network) (2.25.1)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-network) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from msrest>=0.6.21->azure-mgmt-network) (1.3.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from msrest>=0.6.21->azure-mgmt-network) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from msrest>=0.6.21->azure-mgmt-network) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-network) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-network) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.15.0->azure-mgmt-core<2.0.0,>=1.2.0->azure-mgmt-network) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lukast\\miniconda3\\envs\\rl\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-mgmt-network) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# If you need to install the Azure Networking SDK, uncomment the following line.\n",
    "!pip install --upgrade azure-mgmt-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EnvironmentCredential.get_token failed: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "ManagedIdentityCredential.get_token failed: ManagedIdentityCredential authentication unavailable, no managed identity endpoint found.\n",
      "SharedTokenCacheCredential.get_token failed: SharedTokenCacheCredential authentication unavailable. Multiple accounts\n",
      "were found in the cache. Use username and tenant id to disambiguate.\n",
      "VisualStudioCodeCredential.get_token failed: Failed to get Azure user details from Visual Studio Code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Virtual network created successfully:  {'additional_properties': {}, 'id': '/subscriptions/ea5d97cf-5265-410e-85f9-9bbe0ed6d9b5/resourceGroups/ragweed/providers/Microsoft.Network/virtualNetworks/rl_pong_vnet', 'name': 'rl_pong_vnet', 'type': 'Microsoft.Network/virtualNetworks', 'location': 'northeurope', 'tags': None, 'extended_location': None, 'etag': 'W/\"16c8d7bb-cf9d-4679-9a5f-9aaa68889897\"', 'address_space': <azure.mgmt.network.v2021_02_01.models._models_py3.AddressSpace object at 0x000002B661D460A0>, 'dhcp_options': None, 'flow_timeout_in_minutes': None, 'subnets': [], 'virtual_network_peerings': [], 'resource_guid': '0e462770-c519-48b0-b84f-ea5fc56d2ff3', 'provisioning_state': 'Succeeded', 'enable_ddos_protection': False, 'enable_vm_protection': None, 'ddos_protection_plan': None, 'bgp_communities': None, 'ip_allocations': None}\n"
     ]
    }
   ],
   "source": [
    "from azure.mgmt.network import NetworkManagementClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Virtual network name\n",
    "vnet_name =\"rl_pong_vnet\"\n",
    "\n",
    "# Default subnet\n",
    "subnet_name =\"default\"\n",
    "\n",
    "# The Azure subscription you are using\n",
    "subscription_id=ws.subscription_id\n",
    "\n",
    "# The resource group for the reinforcement learning cluster\n",
    "resource_group=ws.resource_group\n",
    "\n",
    "# Azure region of the resource group\n",
    "location=ws.location\n",
    "\n",
    "network_client = NetworkManagementClient(credential=DefaultAzureCredential(), subscription_id=subscription_id)\n",
    "\n",
    "async_vnet_creation = network_client.virtual_networks.begin_create_or_update(\n",
    "    resource_group,\n",
    "    vnet_name,\n",
    "    {\n",
    "        'location': location,\n",
    "        'address_space': {\n",
    "            'address_prefixes': ['10.0.0.0/16']\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "async_vnet_creation.wait()\n",
    "print(\"Virtual network created successfully: \", async_vnet_creation.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up Network Security Group on Virtual Network\n",
    "\n",
    "Depending on your Azure setup, you may need to open certain ports to make it possible for Azure to manage the compute targets that you create.  The ports that need to be opened are described [here](https://docs.microsoft.com/azure/machine-learning/how-to-enable-virtual-network).\n",
    "\n",
    "A common situation is that ports `29876-29877` are closed.  The following code will add a security rule to open these ports.    Or you can do this manually in the [Azure portal](https://portal.azure.com).\n",
    "\n",
    "You may need to modify the code below to match your scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network security group created successfully: {'additional_properties': {}, 'id': '/subscriptions/ea5d97cf-5265-410e-85f9-9bbe0ed6d9b5/resourceGroups/ragweed/providers/Microsoft.Network/networkSecurityGroups/rl_pong_vnet-nsg', 'name': 'rl_pong_vnet-nsg', 'type': 'Microsoft.Network/networkSecurityGroups', 'location': 'northeurope', 'tags': None, 'etag': 'W/\"ada62fd1-63f6-4bb3-b3ff-3b5e97220a57\"', 'security_rules': [<azure.mgmt.network.v2021_02_01.models._models_py3.SecurityRule object at 0x000002B663AB1E80>], 'default_security_rules': [<azure.mgmt.network.v2021_02_01.models._models_py3.SecurityRule object at 0x000002B663AB11C0>, <azure.mgmt.network.v2021_02_01.models._models_py3.SecurityRule object at 0x000002B663AB1100>, <azure.mgmt.network.v2021_02_01.models._models_py3.SecurityRule object at 0x000002B663AB1EB0>, <azure.mgmt.network.v2021_02_01.models._models_py3.SecurityRule object at 0x000002B663AB1B50>, <azure.mgmt.network.v2021_02_01.models._models_py3.SecurityRule object at 0x000002B663AB10D0>, <azure.mgmt.network.v2021_02_01.models._models_py3.SecurityRule object at 0x000002B663AB19A0>], 'network_interfaces': None, 'subnets': None, 'flow_logs': None, 'resource_guid': '39c20b5e-cdf7-48b9-9abc-9092959cee4a', 'provisioning_state': 'Succeeded'}\n",
      "Subnet created successfully: {'additional_properties': {}, 'id': '/subscriptions/ea5d97cf-5265-410e-85f9-9bbe0ed6d9b5/resourceGroups/ragweed/providers/Microsoft.Network/virtualNetworks/rl_pong_vnet/subnets/default', 'name': 'default', 'etag': 'W/\"44d795f2-224d-4bd3-95b4-2b0f9fd5fab6\"', 'type': 'Microsoft.Network/virtualNetworks/subnets', 'address_prefix': '10.0.0.0/24', 'address_prefixes': None, 'network_security_group': <azure.mgmt.network.v2021_02_01.models._models_py3.NetworkSecurityGroup object at 0x000002B661B1BF70>, 'route_table': None, 'nat_gateway': None, 'service_endpoints': None, 'service_endpoint_policies': None, 'private_endpoints': None, 'ip_configurations': None, 'ip_configuration_profiles': None, 'ip_allocations': None, 'resource_navigation_links': None, 'service_association_links': None, 'delegations': [], 'purpose': None, 'provisioning_state': 'Succeeded', 'private_endpoint_network_policies': 'Enabled', 'private_link_service_network_policies': 'Enabled', 'application_gateway_ip_configurations': None}\n"
     ]
    }
   ],
   "source": [
    "import azure.mgmt.network.models\n",
    "\n",
    "security_group_name = vnet_name + '-' + \"nsg\"\n",
    "security_rule_name = \"AllowAML\"\n",
    "\n",
    "# Create a network security group\n",
    "nsg_params = azure.mgmt.network.models.NetworkSecurityGroup(\n",
    "    location=location,\n",
    "    security_rules=[\n",
    "        azure.mgmt.network.models.SecurityRule(\n",
    "            name=security_rule_name,\n",
    "            access=azure.mgmt.network.models.SecurityRuleAccess.allow,\n",
    "            description='Reinforcement Learning in Azure Machine Learning rule',\n",
    "            destination_address_prefix='*',\n",
    "            destination_port_range='29876-29877',\n",
    "            direction=azure.mgmt.network.models.SecurityRuleDirection.inbound,\n",
    "            priority=400,\n",
    "            protocol=azure.mgmt.network.models.SecurityRuleProtocol.tcp,\n",
    "            source_address_prefix='BatchNodeManagement',\n",
    "            source_port_range='*'\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "async_nsg_creation = network_client.network_security_groups.begin_create_or_update(\n",
    "    resource_group,\n",
    "    security_group_name,\n",
    "    nsg_params,\n",
    ")\n",
    "\n",
    "async_nsg_creation.wait() \n",
    "print(\"Network security group created successfully:\", async_nsg_creation.result())\n",
    "\n",
    "network_security_group = network_client.network_security_groups.get(\n",
    "    resource_group,\n",
    "    security_group_name,\n",
    ")\n",
    "\n",
    "# Define a subnet to be created with network security group\n",
    "subnet = azure.mgmt.network.models.Subnet(\n",
    "            id='default',\n",
    "            address_prefix='10.0.0.0/24',\n",
    "            network_security_group=network_security_group\n",
    "            )\n",
    "    \n",
    "# Create subnet on virtual network\n",
    "async_subnet_creation = network_client.subnets.begin_create_or_update(\n",
    "    resource_group_name=resource_group,\n",
    "    virtual_network_name=vnet_name,\n",
    "    subnet_name=subnet_name,\n",
    "    subnet_parameters=subnet\n",
    ")\n",
    "\n",
    "async_subnet_creation.wait()\n",
    "print(\"Subnet created successfully:\", async_subnet_creation.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the virtual network security rules\n",
    "Ensure that the virtual network is configured correctly with required ports open. It is possible that you have configured rules with broader range of ports that allows ports 29876-29877 to be opened. Kindly review your network security group rules.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EnvironmentCredential.get_token failed: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n",
      "ManagedIdentityCredential.get_token failed: ManagedIdentityCredential authentication unavailable, no managed identity endpoint found.\n",
      "SharedTokenCacheCredential.get_token failed: SharedTokenCacheCredential authentication unavailable. Multiple accounts\n",
      "were found in the cache. Use username and tenant id to disambiguate.\n",
      "VisualStudioCodeCredential.get_token failed: Failed to get Azure user details from Visual Studio Code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFORMATION: Rule matched with required ports. Subnet: default Rule: AllowAML\n",
      "INFORMATION: Network security group rules for your virtual network are saved in file rl_pong_vnet.csv\n"
     ]
    }
   ],
   "source": [
    "from files.networkutils import *\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "check_vnet_security_rules(DefaultAzureCredential(), ws.subscription_id, ws.resource_group, vnet_name, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create compute targets\n",
    "\n",
    "In this example, we show how to set up separate compute targets for the Ray head and Ray worker nodes.\n",
    "\n",
    "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.\n",
    "\n",
    "#### Create head compute target\n",
    "\n",
    "First we define the head cluster with GPU for the Ray head node. One CPU of the head node will be used for the Ray head process and the rest of the CPUs will be used by the Ray worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found head compute target. just use it head-gpu\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "# Choose a name for the Ray head cluster\n",
    "head_compute_name = 'head-gpu'\n",
    "head_compute_min_nodes = 0\n",
    "head_compute_max_nodes = 2\n",
    "\n",
    "# This example uses GPU VM. For using CPU VM, set SKU to STANDARD_D2_V2\n",
    "head_vm_size = 'STANDARD_NC6'\n",
    "\n",
    "if head_compute_name in ws.compute_targets:\n",
    "    head_compute_target = ws.compute_targets[head_compute_name]\n",
    "    if head_compute_target and type(head_compute_target) is AmlCompute:\n",
    "        if head_compute_target.provisioning_state == 'Succeeded':\n",
    "            print('found head compute target. just use it', head_compute_name)\n",
    "        else: \n",
    "            raise Exception(\n",
    "                'found head compute target but it is in state', head_compute_target.provisioning_state)\n",
    "else:\n",
    "    print('creating a new head compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=head_vm_size,\n",
    "        min_nodes=head_compute_min_nodes, \n",
    "        max_nodes=head_compute_max_nodes,\n",
    "        vnet_resourcegroup_name=ws.resource_group,\n",
    "        vnet_name=vnet_name,\n",
    "        subnet_name='default')\n",
    "\n",
    "    # Create the cluster\n",
    "    head_compute_target = ComputeTarget.create(ws, head_compute_name, provisioning_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    head_compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(head_compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create worker compute target\n",
    "\n",
    "Now we create a compute target with CPUs for the additional Ray worker nodes. CPUs in these worker nodes are used by Ray worker processes. Each Ray worker node, depending on the CPUs on the node, may have multiple Ray worker processes. There can be multiple worker tasks on each worker process (core)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found worker compute target. just use it worker-cpu\n"
     ]
    }
   ],
   "source": [
    "# Choose a name for your Ray worker compute target\n",
    "worker_compute_name = 'worker-cpu'\n",
    "worker_compute_min_nodes = 0 \n",
    "worker_compute_max_nodes = 4\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\n",
    "worker_vm_size = 'STANDARD_D2_V2'\n",
    "\n",
    "# Create the compute target if it hasn't been created already\n",
    "if worker_compute_name in ws.compute_targets:\n",
    "    worker_compute_target = ws.compute_targets[worker_compute_name]\n",
    "    if worker_compute_target and type(worker_compute_target) is AmlCompute:\n",
    "        if worker_compute_target.provisioning_state == 'Succeeded':\n",
    "            print('found worker compute target. just use it', worker_compute_name)\n",
    "        else: \n",
    "            raise Exception(\n",
    "                'found worker compute target but it is in state', head_compute_target.provisioning_state)\n",
    "else:\n",
    "    print('creating a new worker compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=worker_vm_size,\n",
    "        min_nodes=worker_compute_min_nodes,\n",
    "        max_nodes=worker_compute_max_nodes,\n",
    "        vnet_resourcegroup_name=ws.resource_group,\n",
    "        vnet_name=vnet_name,\n",
    "        subnet_name='default')\n",
    "\n",
    "    # Create the compute target\n",
    "    worker_compute_target = ComputeTarget.create(ws, worker_compute_name, provisioning_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    worker_compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(worker_compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Pong Agent\n",
    "To facilitate reinforcement learning, Azure Machine Learning Python SDK provides a high level abstraction, the _ReinforcementLearningEstimator_ class, which allows users to easily construct  reinforcement learning run configurations for the underlying reinforcement learning framework.  Reinforcement Learning in Azure Machine Learning supports the open source [Ray framework](https://ray.io/) and its highly customizable [RLLib](https://ray.readthedocs.io/en/latest/rllib.html#rllib-scalable-reinforcement-learning). In this section we show how to use _ReinforcementLearningEstimator_ and Ray/RLLib framework to train a Pong playing agent.\n",
    "\n",
    "\n",
    "### Define worker configuration\n",
    "Define a `WorkerConfiguration` using your worker compute target. We specify the number of nodes in the worker compute target to be used for training and additional PIP packages to install on those nodes as a part of setup.\n",
    "In this case, we define the PIP packages as dependencies for both head and worker nodes. With this setup, the game simulations will run directly on the worker compute nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.train.rl import WorkerConfiguration\n",
    "\n",
    "# Specify the Ray worker configuration\n",
    "worker_conf = WorkerConfiguration(\n",
    "    \n",
    "    # Azure Machine Learning compute target to run Ray workers\n",
    "    compute_target=worker_compute_target, \n",
    "    \n",
    "    # Number of worker nodes\n",
    "    node_count=4,\n",
    "    \n",
    "    # GPU\n",
    "    use_gpu=False, \n",
    "    \n",
    "    # PIP packages to use\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reinforcement learning estimator\n",
    "\n",
    "The `ReinforcementLearningEstimator` is used to submit a job to Azure Machine Learning to start the Ray experiment run. We define the training script parameters here that will be passed to the estimator. \n",
    "\n",
    "We specify `episode_reward_mean` to 18 as we want to stop the training as soon as the trained agent reaches an average win margin of at least 18 point over opponent over all episodes in the training epoch.\n",
    "Number of Ray worker processes are defined by parameter `num_workers`. We set it to 13 as we have 13 CPUs available in our compute targets. Multiple Ray worker processes parallelizes agent training and helps in achieving our goal faster. \n",
    "\n",
    "```\n",
    "Number of CPUs in head_compute_target = 6 CPUs in 1 node = 6\n",
    "Number of CPUs in worker_compute_target = 2 CPUs in each of 4 nodes = 8\n",
    "Number of CPUs available = (Number of CPUs in head_compute_target) + (Number of CPUs in worker_compute_target) - (1 CPU for head node) = 6 + 8 - 1 = 13\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.train.rl import ReinforcementLearningEstimator, Ray\n",
    "\n",
    "training_algorithm = \"IMPALA\"\n",
    "rl_environment = \"PongNoFrameskip-v4\"\n",
    "\n",
    "# video_capture = True\n",
    "\n",
    "# if video_capture:\n",
    "#     algorithm_config = '\\'{\"num_gpus\": 0, \"num_workers\": 13, \"monitor\": true}\\''\n",
    "# else:\n",
    "#     algorithm_config = '\\'{\"num_gpus\": 0, \"num_workers\": 13, \"monitor\": false}\\''\n",
    "\n",
    "\n",
    "# Training script parameters\n",
    "script_params = {\n",
    "    \n",
    "    # Training algorithm, IMPALA in this case\n",
    "    \"--run\": training_algorithm,\n",
    "    \n",
    "    # Environment, Pong in this case\n",
    "    \"--env\": rl_environment,\n",
    "    \n",
    "    # Add additional single quotes at the both ends of string values as we have spaces in the \n",
    "    # string parameters, outermost quotes are not passed to scripts as they are not actually part of string\n",
    "    # Number of GPUs\n",
    "    # Number of ray workers\n",
    "    \"--config\": '\\'{\"num_gpus\": 1, \"num_workers\": 13}\\'',\n",
    "    #\"--config\": algorithm_config,\n",
    "    \n",
    "    # Target episode reward mean to stop the training\n",
    "    # Total training time in seconds\n",
    "    \"--stop\": '\\'{\"episode_reward_mean\": 18, \"time_total_s\": 3600}\\'',\n",
    "    \n",
    "       # Frequency of taking checkpoints\n",
    "    \"--checkpoint-freq\": 2,\n",
    "    \n",
    "    # If a checkpoint should be taken at the end - optional argument with no value\n",
    "    \"--checkpoint-at-end\": \"\",\n",
    "    \n",
    "    \n",
    "    # Log directory\n",
    "    \"--local-dir\": './logs'\n",
    "}\n",
    "\n",
    "\n",
    "# xvfb_env = None\n",
    "# if video_capture:\n",
    "#     # Ray's video capture support requires to run everything under a headless display driver called (xvfb).\n",
    "#     # There are two parts to this:\n",
    "#     # 1. Use a custom docker file with proper instructions to install xvfb, ffmpeg, python-opengl\n",
    "#     # and other dependencies.\n",
    "   \n",
    "#     with open(\"files/docker/Dockerfile\", \"r\") as f:\n",
    "#         dockerfile=f.read()\n",
    "\n",
    "#     xvfb_env = Environment(name='xvfb-vdisplay')\n",
    "#     xvfb_env.docker.enabled = True\n",
    "#     xvfb_env.docker.base_image = None\n",
    "#     xvfb_env.docker.base_dockerfile = dockerfile\n",
    "    \n",
    "#     # 2.  Execute the Python process via the xvfb-run command to set up the headless display driver.\n",
    "#     xvfb_env.python.user_managed_dependencies = True\n",
    "#     xvfb_env.python.interpreter_path = \"xvfb-run -s '-screen 0 640x480x16 -ac +extension GLX +render' python\"\n",
    "\n",
    "\n",
    "\n",
    "#  Reinforcement learning estimator\n",
    "rl_estimator = ReinforcementLearningEstimator(\n",
    "    \n",
    "    # Location of source files\n",
    "    source_directory='files',\n",
    "    \n",
    "    # Python script file\n",
    "    entry_script=\"pong_rllib.py\",\n",
    "    \n",
    "    # Parameters to pass to the script file\n",
    "    # Defined above.\n",
    "    script_params=script_params,\n",
    "    \n",
    "    # The Azure Machine Learning compute target set up for Ray head nodes\n",
    "    compute_target=head_compute_target,\n",
    "    \n",
    "    # GPU usage\n",
    "    use_gpu=True,\n",
    "    \n",
    "    # Reinforcement learning framework. Currently must be Ray.\n",
    "    rl_framework=Ray('0.8.3'),\n",
    "    \n",
    "    # Ray worker configuration defined above.\n",
    "    worker_configuration=worker_conf,\n",
    "    \n",
    "    # How long to wait for whole cluster to start\n",
    "    cluster_coordination_timeout_seconds=3600,\n",
    "    \n",
    "    # Maximum time for the whole Ray job to run\n",
    "    # This will cut off the run after an hour\n",
    "    max_run_duration_seconds=3600, ##lowered from 3600 for code test\n",
    "    \n",
    "    # Allow the docker container Ray runs in to make full use\n",
    "    # of the shared memory available from the host OS.\n",
    "    shm_size=24*1024*1024*1024 #,\n",
    "    \n",
    "      # Custom environmnet for Xvfb\n",
    "    #environment=xvfb_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training script\n",
    "As recommended in [RLlib](https://ray.readthedocs.io/en/latest/rllib.html) documentations, we use Ray [Tune](https://ray.readthedocs.io/en/latest/tune.html) API to run the training algorithm. All the RLlib built-in trainers are compatible with the Tune API. Here we use tune.run() to execute a built-in training algorithm. For convenience, down below you can see part of the entry script where we make this call.\n",
    "\n",
    "```python\n",
    "    tune.run(\n",
    "        run_or_experiment=args.run,\n",
    "        config={\n",
    "            \"env\": args.env,\n",
    "            \"num_gpus\": args.config[\"num_gpus\"],\n",
    "            \"num_workers\": args.config[\"num_workers\"],\n",
    "            \"callbacks\": {\"on_train_result\": callbacks.on_train_result},\n",
    "            \"sample_batch_size\": 50,\n",
    "            \"train_batch_size\": 1000,\n",
    "            \"num_sgd_iter\": 2,\n",
    "            \"num_data_loader_buffers\": 2,\n",
    "            \"model\": {\"dim\": 42},\n",
    "        },\n",
    "        stop=args.stop,\n",
    "        local_dir='./logs')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the estimator to start a run\n",
    "Now we use the rl_estimator configured above to submit a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=rl_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the run\n",
    "\n",
    "Azure Machine Learning provides a Jupyter widget to show the status of an experiment run. You could use this widget to monitor the status of the runs. The widget shows the list of two child runs, one for head compute target run and one for worker compute target run. You can click on the link under **Status** to see the details of the child run. It will also show the metrics being logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fcf08c883949ba96fb4e95c9c2bcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_RLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'sdk_vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/rllib-pong-multi-node_1629900618_d150b318?wsid=/subscriptions/ea5d97cf-5265-410e-85f9-9bbe0ed6d9b5/resourcegroups/ragweed/workspaces/lukasml&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"rllib-pong-multi-node_1629900618_d150b318\", \"run_properties\": {\"run_id\": \"rllib-pong-multi-node_1629900618_d150b318\", \"created_utc\": \"2021-08-25T14:10:19.399376Z\", \"properties\": {\"azureml.git.repository_uri\": \"https://github.com/LukasSteindl/MachineLearningNotebooks.git\", \"mlflow.source.git.repoURL\": \"https://github.com/LukasSteindl/MachineLearningNotebooks.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"4619d047927b59fba38a7573e68c58c1e94d0cbe\", \"mlflow.source.git.commit\": \"4619d047927b59fba38a7573e68c58c1e94d0cbe\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"cluster_coordination_timeout_seconds\": \"3600\"}, \"end_time_utc\": \"2021-08-25T14:40:48.932727Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/reinforcementlearning.txt\": \"https://lukasml2977733755.blob.core.windows.net/azureml/ExperimentRun/dcid.rllib-pong-multi-node_1629900618_d150b318/azureml-logs/reinforcementlearning.txt?sv=2019-07-07&sr=b&sig=PIWHplNZqDISh%2F7%2Fzq4GbJ8uP1v3s78NW9R6u1Hp%2FlU%3D&st=2021-08-25T15%3A00%3A27Z&se=2021-08-25T23%3A10%3A27Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/reinforcementlearning.txt\"]], \"run_duration\": \"0:30:29\", \"run_number\": \"4\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"cluster_coordination_timeout_seconds\": \"3600\"}, \"child_runs\": [{\"run_id\": \"rllib-pong-multi-node_1629900618_d150b318_worker\", \"run_number\": 6, \"metric\": null, \"status\": \"Canceled\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-08-25T14:14:37.71504Z\", \"end_time\": \"2021-08-25T14:40:52.591712Z\", \"created_time\": \"2021-08-25T14:10:26.618486Z\", \"created_time_dt\": \"2021-08-25T14:10:26.618486Z\", \"duration\": \"0:30:25\"}, {\"run_id\": \"rllib-pong-multi-node_1629900618_d150b318_head\", \"run_number\": 5, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-08-25T14:13:08.768917Z\", \"end_time\": \"2021-08-25T14:40:40.157836Z\", \"created_time\": \"2021-08-25T14:10:26.207761Z\", \"created_time_dt\": \"2021-08-25T14:10:26.207761Z\", \"duration\": \"0:30:13\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-08-25T14:10:19.5347820Z][Info]Starting reinforcement learning run with id rllib-pong-multi-node_1629900618_d150b318.\\n[2021-08-25T14:10:25.3617519Z][Info]Starting head node child run with id rllib-pong-multi-node_1629900618_d150b318_head.\\n[2021-08-25T14:10:26.2849195Z][Info]Starting worker child run with id rllib-pong-multi-node_1629900618_d150b318_worker.\\n[2021-08-25T14:40:51.3548289Z][Info]Some child runs have reached terminal state. All active child runs will be cancelled. The run Ids that reached terminal state are: rllib-pong-multi-node_1629900618_d150b318_head.\\n[2021-08-25T14:40:51.4153896Z][Info]Updating status of child run with Id rllib-pong-multi-node_1629900618_d150b318_worker from Running to Completed, since one of the child runs has reached a terminal state.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.33.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the run\n",
    "\n",
    "To stop the run, call `run.cancel()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below to cancel the run\n",
    "# run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for completion\n",
    "Wait for the run to complete before proceeding. If you want to stop the run, you may skip this and move to next section below. \n",
    "\n",
    "**Note: The run may take anywhere from 30 minutes to 45 minutes to complete.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"environment\": \"northeurope\",\n    \"location\": \"northeurope\",\n    \"time\": \"2021-08-25T15:08:39.793455Z\",\n    \"componentName\": \"jobserver\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"environment\\\": \\\"northeurope\\\",\\n    \\\"location\\\": \\\"northeurope\\\",\\n    \\\"time\\\": \\\"2021-08-25T15:08:39.793455Z\\\",\\n    \\\"componentName\\\": \\\"jobserver\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3817306bf75a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\rl\\lib\\site-packages\\azureml\\core\\run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[1;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfinal_details\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageParameters\": {},\n        \"details\": []\n    },\n    \"environment\": \"northeurope\",\n    \"location\": \"northeurope\",\n    \"time\": \"2021-08-25T15:08:39.793455Z\",\n    \"componentName\": \"jobserver\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"details\\\": []\\n    },\\n    \\\"environment\\\": \\\"northeurope\\\",\\n    \\\"location\\\": \\\"northeurope\\\",\\n    \\\"time\\\": \\\"2021-08-25T15:08:39.793455Z\\\",\\n    \\\"componentName\\\": \\\"jobserver\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the agent during training\n",
    "\n",
    "Let's get the reward metrics for the training run agent and observe how the agent's rewards improved over the training iterations and how the agent learns to win the Pong game. \n",
    "\n",
    "Collect the episode reward metrics from the worker run's metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the reward metrics from worker run\n",
    "episode_reward_mean = run.get_metrics(name='episode_reward_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the reward metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(episode_reward_mean['episode_reward_mean'])\n",
    "plt.xlabel('training_iteration')\n",
    "plt.ylabel('episode_reward_mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added code to render Video: (taken from cart pole)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(Experiment: rllib-pong-multi-node,\n",
       " Id: rllib-pong-multi-node_1629900618_d150b318_worker,\n",
       " Type: azureml.scriptrun,\n",
       " Status: Canceled),\n",
       " Run(Experiment: rllib-pong-multi-node,\n",
       " Id: rllib-pong-multi-node_1629900618_d150b318_head,\n",
       " Type: azureml.scriptrun,\n",
       " Status: Completed)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(run.get_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of child runs: 2\n",
      "Child run info:\n",
      "Run(Experiment: rllib-pong-multi-node,\n",
      "Id: rllib-pong-multi-node_1629900618_d150b318_head,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "child_run_0 = None\n",
    "timeout = 30\n",
    "while timeout > 0 and not child_run_0:\n",
    "    child_runs = list(run.get_children())\n",
    "    print('Number of child runs:', len(child_runs))\n",
    "    if len(child_runs) > 0:\n",
    "        child_run_0 = child_runs[1]\n",
    "        break\n",
    "    time.sleep(2) # Wait for 2 seconds\n",
    "    timeout -= 2\n",
    "\n",
    "print('Child run info:')\n",
    "print(child_run_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "\n",
    "run_id = child_run_0.id # Or set to run id of a completed run (e.g. 'rl-cartpole-v0_1587572312_06e04ace_head')\n",
    "child_run_0 = Run(exp, run_id=run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that during the training over multiple episodes, the agent learns to win the Pong game against opponent with our target of 18 points in each episode of 21 points.\n",
    "**Congratulations!! You have trained your Pong agent to win a game.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts path: logs\\IMPALA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from os import path\n",
    "from distutils import dir_util\n",
    "\n",
    "training_artifacts_path = path.join(\"logs\", training_algorithm)\n",
    "print(\"Training artifacts path:\", training_artifacts_path)\n",
    "\n",
    "if path.exists(training_artifacts_path):\n",
    "    dir_util.remove_tree(training_artifacts_path)\n",
    "\n",
    "# Download run artifacts to local compute\n",
    "child_run_0.download_files(training_artifacts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in path: logs\\IMPALA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# A helper function to find checkpoint files in a directory\n",
    "def find_checkpoints(file_path):\n",
    "    print(\"Looking in path:\", file_path)\n",
    "    checkpoints = []\n",
    "    for root, _, files in os.walk(file_path):\n",
    "        for name in files:\n",
    "            if os.path.basename(root).startswith('checkpoint_'):\n",
    "                checkpoints.append(path.join(root, name))\n",
    "    return checkpoints\n",
    "\n",
    "checkpoint_files = find_checkpoints(training_artifacts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoints: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-8a862ddc0362>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Checkpoints:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_numbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mlast_checkpoint_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_numbers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Last checkpoint number:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_checkpoint_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Find checkpoints and last checkpoint number\n",
    "checkpoint_numbers = []\n",
    "for file in checkpoint_files:\n",
    "    file = os.path.basename(file)\n",
    "    if file.startswith('checkpoint-') and not file.endswith('.tune_metadata'):\n",
    "        checkpoint_numbers.append(int(file.split('-')[-1]))\n",
    "\n",
    "print(\"Checkpoints:\", checkpoint_numbers)\n",
    "\n",
    "last_checkpoint_number = max(checkpoint_numbers)\n",
    "print(\"Last checkpoint number:\", last_checkpoint_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {    \n",
    "    # Checkpoint number of the checkpoint from which to roll out\n",
    "    \"--checkpoint-number\": last_checkpoint_number,\n",
    "\n",
    "    # Training algorithm\n",
    "    \"--run\": training_algorithm,\n",
    "    \n",
    "    # Training environment\n",
    "    \"--env\": rl_environment,\n",
    "    \n",
    "    # Algorithm-specific parameters\n",
    "    \"--config\": '{}',\n",
    "    \n",
    "    # Number of rollout steps \n",
    "    \"--steps\": 2000,\n",
    "    \n",
    "    # If should repress rendering of the environment\n",
    "    \"--no-render\": \"\",\n",
    "    \n",
    "    # The place where recorded videos will be stored\n",
    "    \"--video-dir\": \"./logs/video\"\n",
    "}\n",
    "\n",
    "if video_capture:\n",
    "    script_params.pop(\"--no-render\")\n",
    "else:\n",
    "    script_params.pop(\"--video-dir\")\n",
    "\n",
    "\n",
    "# Ray's video capture support requires to run everything under a headless display driver called (xvfb).\n",
    "# There are two parts to this:\n",
    "\n",
    "# 1. Use a custom docker file with proper instructions to install xvfb, ffmpeg, python-opengl\n",
    "# and other dependencies.\n",
    "# Note: Even when the rendering is off pyhton-opengl is needed.\n",
    "\n",
    "with open(\"files/docker/Dockerfile\", \"r\") as f:\n",
    "    dockerfile=f.read()\n",
    "\n",
    "xvfb_env = Environment(name='xvfb-vdisplay')\n",
    "xvfb_env.docker.enabled = True\n",
    "xvfb_env.docker.base_image = None\n",
    "xvfb_env.docker.base_dockerfile = dockerfile\n",
    "    \n",
    "# 2.  Execute the Python process via the xvfb-run command to set up the headless display driver.\n",
    "xvfb_env.python.user_managed_dependencies = True\n",
    "if video_capture:\n",
    "    xvfb_env.python.interpreter_path = \"xvfb-run -s '-screen 0 640x480x16 -ac +extension GLX +render' python\"\n",
    "\n",
    "\n",
    "rollout_estimator = ReinforcementLearningEstimator(\n",
    "    # Location of source files\n",
    "    source_directory='files',\n",
    "    \n",
    "    # Python script file\n",
    "    entry_script='cartpole_rollout.py',\n",
    "    \n",
    "    # A dictionary of arguments to pass to the rollout script specified in ``entry_script``\n",
    "    script_params = script_params,\n",
    "    \n",
    "    # Data inputs\n",
    "    inputs=[\n",
    "        checkpoint_ds.as_named_input('artifacts_dataset'),\n",
    "        checkpoint_ds.as_named_input('artifacts_path').as_mount()],\n",
    "    \n",
    "    # The Azure Machine Learning compute target set up for Ray head nodes\n",
    "    compute_target=compute_target,\n",
    "    \n",
    "    # Reinforcement learning framework. Currently must be Ray.\n",
    "    rl_framework=Ray(),\n",
    "    \n",
    "    # Custom environmnet for Xvfb\n",
    "    environment=xvfb_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_run = exp.submit(rollout_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(rollout_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_runs = list(rollout_run.get_children())\n",
    "print('Number of child runs:', len(child_runs))\n",
    "child_run_0 = child_runs[0]\n",
    "\n",
    "# Download rollout artifacts\n",
    "rollout_artifacts_path = path.join(\"logs\", \"rollout\")\n",
    "print(\"Rollout artifacts path:\", rollout_artifacts_path)\n",
    "\n",
    "if path.exists(rollout_artifacts_path):\n",
    "    dir_util.remove_tree(rollout_artifacts_path)\n",
    "\n",
    "# Download videos to local compute\n",
    "child_run_0.download_files(\"logs/video\", output_directory = rollout_artifacts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files = find_movies(rollout_artifacts_path)\n",
    "mp4_files.sort()\n",
    "last_movie = mp4_files[-1] if len(mp4_files) > 1 else None\n",
    "print(\"Last movie:\", last_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_movie = mp4_files[-1] if len(mp4_files) > 0 else None\n",
    "print(\"Last movie:\", last_movie)\n",
    "\n",
    "display_movie(last_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "For your convenience, below you can find code snippets to clean up any resources created as part of this tutorial that you don't wish to retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To archive the created experiment:\n",
    "#experiment.archive()\n",
    "\n",
    "# To delete the compute targets:\n",
    "#head_compute_target.delete()\n",
    "#worker_compute_target.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "In this example, you learned how to solve distributed reinforcement learning training problems using head and worker compute targets. This was an introductory tutorial on Reinforement Learning in Azure Machine Learning service offering. We would love to hear your feedback to build the features you need!"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "vineetg"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "notice": "Copyright (c) Microsoft Corporation. All rights reserved.Ã¢â‚¬Â¯Licensed under the MIT License.Ã¢â‚¬Â¯ "
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
